{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd01072e0526ace921920c945980564f480b3d3170b4dc7a8d6cb33c09ebdd84565",
   "display_name": "Python 3.9.1 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook applies header detection and table picking methods to Detectron and Textract output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_row_remover(df):\n",
    "    #Drop rows that have only one filled-in value\n",
    "    df['na_count'] = df.isnull().sum(axis=1)\n",
    "    df = df[df.na_count < (len(df.columns)-2)]\n",
    "    df = df.drop('na_count', axis=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_postproc(path):\n",
    "    # Process documents\n",
    "    if 'detectron' in str(path):\n",
    "        df = pd.read_csv(\"s3:/\" + str(path)).iloc[:, 1:] # For detectron, drop first (index) column\n",
    "        df = extra_row_remover(df)\n",
    "        # Use shape of table heuristic to determine if the table is useful or not\n",
    "        # if row*col count <=15, classify table as header or other information\n",
    "        # Analysis was conducted and documented in Damian Doc Extraction Whiteboard\n",
    "        if df.shape[0] * df.shape[1] <= 15:\n",
    "            # TODO: document that this table was labelled as extraneous somehow\n",
    "            print(f'Table: {path} contains minimal data, not processed')\n",
    "        else:\n",
    "            df_detectron = nlp_proc.header_detector(df, mf_rr_kb).replace_header()\n",
    "            _,zscores = nlp_proc.header_detector(df, mf_rr_kb).get_header_candidates()\n",
    "            zscores = pd.DataFrame(zscores, columns=['idx','v','z'])\n",
    "            # Save output to S3\n",
    "            df_detectron.to_csv(postproc_output_dir + \"detectron/\" + UUID + \"/\" + str(path).split('/')[-1])\n",
    "            zscores.to_csv(postproc_output_dir + \"detectron/\" + UUID + \"/_zscores_\" + str(path).split('/')[-1])\n",
    "\n",
    "    elif 'textract' in str(path):\n",
    "        with path.open() as f:\n",
    "            content = f.readlines()\n",
    "        index = [x for x in range(len(content)) if 'Table' in content[x]]\n",
    "        if len(index) > 1:\n",
    "            row_len = [len(x) for x in content]\n",
    "            print(f\"Table: {path} has multiple subtables, code in development\")\n",
    "        else:\n",
    "                df = pd.read_csv(\"s3:/\" + str(path), skiprows=1, header=None)\n",
    "                df = extra_row_remover(df)\n",
    "                df_textract = nlp_proc.header_detector(df, mf_rr_kb).replace_header()\n",
    "                _,zscores = nlp_proc.header_detector(df, mf_rr_kb).get_header_candidates()\n",
    "                zscores = pd.DataFrame(zscores, columns=['idx','v','z'])\n",
    "                # Save output to S3\n",
    "                df_textract.to_csv(postproc_output_dir + \"textract/\" + UUID + \"/\" + str(path).split('/')[-1])\n",
    "                zscores.to_csv(postproc_output_dir + \"textract/\" + UUID + \"/_zscores_\" + str(path).split('/')[-1])\n",
    "    else:\n",
    "        print('Extraction source not recognized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textract can have multiple tables in a single CSV - this would be indicated by a row that begins with \"Table\" and has nothing else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from s3path import S3Path\n",
    "\n",
    "# Import custom modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#!python -m spacy download en_core_web_lg\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from normalize import organize, nlp_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters should be UUID and source (Detectron vs. Textract... eventually Google DocumentAI too)\n",
    "UUID = 'f3d3fe84-a2ca-11eb-9113-666251992ff6'\n",
    "postproc_output_dir = \"s3://tab-data-extraction-sandbox/postproc_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Multifamily header knowledge base\n",
    "mf_rr_kb = pd.read_csv('s3://tab-data-extraction-sandbox/manual_review/rr_multifamily_header.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_path = S3Path('/dataingest-pdfextraction-output/')\n",
    "detectron_paths = list(rr_path.glob('detectron_output/' + UUID + '/*.csv'))\n",
    "textract_paths = list(rr_path.glob('textract_output/' + UUID + '.pdf-analysis/*tables.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "S3Path('/dataingest-pdfextraction-output/detectron_output/f3d3fe84-a2ca-11eb-9113-666251992ff6/Page 4 - Table 2.csv')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "detectron_paths[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectron_example = pd.read_csv(\"s3:/\" + str(detectron_paths[23])).iloc[:, 1:] # For detectron, drop first (index) column\n",
    "textract_example = pd.read_csv(\"s3:/\" + str(textract_paths[0]), skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-1-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-10-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-11-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-12-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-13-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-14-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-15-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-16-tables.csv\n",
      "Table: /dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-16-tables.csv has multiple subtables, code in development\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-2-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-3-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-4-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-5-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-6-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-7-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-8-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "/dataingest-pdfextraction-output/textract_output/f3d3fe84-a2ca-11eb-9113-666251992ff6.pdf-analysis/page-9-tables.csv\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n",
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n"
     ]
    }
   ],
   "source": [
    "'''for p in detectron_paths:\n",
    "    extraction_postproc(p)\n",
    "'''\n",
    "for p in textract_paths:\n",
    "    print(p)\n",
    "    extraction_postproc(p)"
   ]
  },
  {
   "source": [
    "### For picking between Textract and Detectron, also consider the number of pages with results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Apply header detection to Detectron and Textract"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extraneous rows\n",
    "df_detectron = extra_row_remover(detectron_example)\n",
    "df_textract = extra_row_remover(textract_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "../normalize/nlp_proc.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n  sim_mat = [[x.similarity(y) for x in to_map_pipe] for y in kb_pipe]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unit Unit Type Unit Resident Sq Ft  \\\n",
       "0   06315    3698a1     592.00 t2665776   \n",
       "1   06316    3698a1     592.00 t2649445   \n",
       "2   06317    3698a1     592.00 t3732813   \n",
       "3   06318    3698b1   1,169.00 t2647017   \n",
       "4   07101    3698b2   1,259.00 t2724209   \n",
       "5   07102   3698a3g     737.00 t2666531   \n",
       "6   07103   3698a3g     737.00 t2871216   \n",
       "7   07104   3698a3g     737.00 t2742020   \n",
       "8   07105   3698a2g     826.00 t2738920   \n",
       "9   07106   3698a5g     791.00 t3421286   \n",
       "10  07107   3698a4g     855.00 t2709215   \n",
       "11  07108   3698b3g   1,001.00 t2632603   \n",
       "12  07109   3698b3g   1,001.00 t2708300   \n",
       "13  07110  3698a3ga     737.00 t2920470   \n",
       "14  07111   3698b3g   1,001.00 t2712755   \n",
       "15  07112   3698b3g   1,001.00 t2754122   \n",
       "16  07113   3698a4g     855.00 t2710661   \n",
       "17  07114   3698a5g     791.00 t0761733   \n",
       "18  07115   3698a2g     826.00 t0734926   \n",
       "19  07116   3698a3g     737.00 t2740896   \n",
       "20  07117   3698a3g     737.00 t2687782   \n",
       "21  07118   3698a3g     737.00 t3455875   \n",
       "22  07119    3698b2   1,259.00 t2708998   \n",
       "23  07120    3698b1   1,169.00 t3689489   \n",
       "24  07135    3698b1   1,169.00 t2766515   \n",
       "25  07201    3698b2   1,259.00 t3820388   \n",
       "26  07202    3698a3     727.00 t2202133   \n",
       "27  07203    3698a3     727.00 t2705701   \n",
       "28  07204    3698a3       727.00 VACANT   \n",
       "29  07205    3698a2     819.00 t2896832   \n",
       "30  07206    3698a5     789.00 t3825189   \n",
       "\n",
       "                                Name\\nMarket Rent Actual Rent  \\\n",
       "0                          Keilee Green\\n1,086.00    1,078.00   \n",
       "1                          Rodney Oatts\\n1,086.00    1,139.00   \n",
       "2                  Nicholas Gugliemelli\\n1,086.00    1,041.00   \n",
       "3                         Tyeesha Smith\\n1,632.00    1,459.00   \n",
       "4   Alexandre Claro Bitencourt De Sousa\\n1,823.00    1,521.00   \n",
       "5                        Sylvia Freeman\\n1,296.00    1,210.00   \n",
       "6                            Mark Woods\\n1,296.00    1,204.00   \n",
       "7                       Kayode Holbrook\\n1,296.00    1,273.00   \n",
       "8                 Jonathan Robertson Jr\\n1,483.00    1,519.00   \n",
       "9                        William Fulton\\n1,408.00    1,530.00   \n",
       "10                         David Harris\\n1,376.00    1,406.00   \n",
       "11                        Kaitlyn Skabo\\n1,626.00    1,575.00   \n",
       "12                          Jose Robles\\n1,626.00    1,390.00   \n",
       "13                  Guadalupe Armstrong\\n1,295.00    1,259.00   \n",
       "14                           Billy Nail\\n1,626.00    1,584.00   \n",
       "15                          Wendy Bacon\\n1,726.00    1,607.00   \n",
       "16                           Janice Ahn\\n1,376.00    1,316.00   \n",
       "17                      Breanna Stewart\\n1,408.00    1,297.00   \n",
       "18                       Joseph Sitters\\n1,483.00    1,354.00   \n",
       "19                     Ferrin Bavousett\\n1,311.00    1,239.00   \n",
       "20                         Jeniva Marin\\n1,311.00    1,283.00   \n",
       "21                         Trace Cooper\\n1,361.00    1,269.00   \n",
       "22                      Tucker Mckinzie\\n1,838.00    1,771.00   \n",
       "23                         Jatyn Taylor\\n1,742.00    1,640.00   \n",
       "24                   Darryl Whitaker Jr\\n1,742.00    1,742.00   \n",
       "25                       Quinton Butler\\n1,903.00    1,549.00   \n",
       "26                         Corey Miller\\n1,242.00    1,189.00   \n",
       "27                     Matthew Martinez\\n1,242.00    1,102.00   \n",
       "28                               VACANT\\n1,192.00        0.00   \n",
       "29                        Kendra Pipkin\\n1,315.00    1,227.00   \n",
       "30                      Hayato Kamohara\\n1,308.00    1,238.00   \n",
       "\n",
       "   Resident Deposit Other Move In Deposit Lease Expiration Move Out    Balance  \n",
       "0            629.50         0.00 8/9/2019         8/8/2021      NaN     132.34  \n",
       "1            100.00        0.00 6/21/2019        6/20/2021      NaN       0.00  \n",
       "2            100.00        0.00 3/11/2019        3/10/2021      NaN       0.00  \n",
       "3            200.00        0.00 5/10/2019         5/9/2021      NaN       0.00  \n",
       "4            200.00         0.00 4/2/2020         2/1/2021      NaN       0.00  \n",
       "5            693.50        0.00 8/16/2019        8/15/2021      NaN       0.00  \n",
       "6            100.00        0.00 1/19/2018        2/18/2021      NaN     681.36  \n",
       "7            100.00        0.00 9/15/2020        9/14/2021      NaN       0.00  \n",
       "8              0.00        0.00 6/18/2020        6/17/2021      NaN    -247.58  \n",
       "9            100.00       0.00 10/27/2018       10/26/2020      NaN     118.00  \n",
       "10           100.00        0.00 2/17/2020        2/16/2021      NaN       0.00  \n",
       "11           200.00       200.00 2/9/2019        2/19/2021      NaN       0.00  \n",
       "12           100.00      200.00 2/12/2020        2/11/2021      NaN       0.00  \n",
       "13           100.00         0.00 2/9/2018         2/8/2021      NaN       0.00  \n",
       "14           200.00        0.00 4/24/2020        4/23/2021      NaN    -454.07  \n",
       "15           200.00      200.00 9/12/2020        9/11/2021      NaN       0.00  \n",
       "16           100.00      100.00 4/24/2020        4/23/2021      NaN       0.00  \n",
       "17           577.50        0.00 5/23/2014         5/8/2021      NaN   1,415.95  \n",
       "18           100.00         0.00 5/2/2014        4/14/2021      NaN      66.06  \n",
       "19           100.00      200.00 8/22/2020        8/21/2021      NaN       0.00  \n",
       "20           100.00       0.00 11/21/2019       11/20/2020      NaN       0.00  \n",
       "21           100.00      200.00 12/7/2018         1/6/2021      NaN       0.00  \n",
       "22           200.00      200.00 9/29/2017        3/28/2021      NaN    -105.00  \n",
       "23           200.00        0.00 2/16/2019        2/17/2021      NaN  10,716.62  \n",
       "24             0.00       0.00 10/17/2020       10/16/2021      NaN     -63.55  \n",
       "25           200.00        0.00 4/26/2019        5/20/2021      NaN       0.00  \n",
       "26           100.00        0.00 6/12/2016        4/11/2021      NaN       0.00  \n",
       "27           100.00        0.00 2/28/2020        2/27/2021      NaN     202.00  \n",
       "28             0.00                  0.00              NaN      NaN       0.00  \n",
       "29           100.00        0.00 2/28/2018        3/27/2021      NaN       0.00  \n",
       "30           100.00        0.00 4/18/2019        3/17/2021      NaN       0.00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unit</th>\n      <th>Unit Type</th>\n      <th>Unit Resident Sq Ft</th>\n      <th>Name\\nMarket Rent</th>\n      <th>Actual Rent</th>\n      <th>Resident Deposit</th>\n      <th>Other Move In Deposit</th>\n      <th>Lease Expiration</th>\n      <th>Move Out</th>\n      <th>Balance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>06315</td>\n      <td>3698a1</td>\n      <td>592.00 t2665776</td>\n      <td>Keilee Green\\n1,086.00</td>\n      <td>1,078.00</td>\n      <td>629.50</td>\n      <td>0.00 8/9/2019</td>\n      <td>8/8/2021</td>\n      <td>NaN</td>\n      <td>132.34</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>06316</td>\n      <td>3698a1</td>\n      <td>592.00 t2649445</td>\n      <td>Rodney Oatts\\n1,086.00</td>\n      <td>1,139.00</td>\n      <td>100.00</td>\n      <td>0.00 6/21/2019</td>\n      <td>6/20/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>06317</td>\n      <td>3698a1</td>\n      <td>592.00 t3732813</td>\n      <td>Nicholas Gugliemelli\\n1,086.00</td>\n      <td>1,041.00</td>\n      <td>100.00</td>\n      <td>0.00 3/11/2019</td>\n      <td>3/10/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>06318</td>\n      <td>3698b1</td>\n      <td>1,169.00 t2647017</td>\n      <td>Tyeesha Smith\\n1,632.00</td>\n      <td>1,459.00</td>\n      <td>200.00</td>\n      <td>0.00 5/10/2019</td>\n      <td>5/9/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>07101</td>\n      <td>3698b2</td>\n      <td>1,259.00 t2724209</td>\n      <td>Alexandre Claro Bitencourt De Sousa\\n1,823.00</td>\n      <td>1,521.00</td>\n      <td>200.00</td>\n      <td>0.00 4/2/2020</td>\n      <td>2/1/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>07102</td>\n      <td>3698a3g</td>\n      <td>737.00 t2666531</td>\n      <td>Sylvia Freeman\\n1,296.00</td>\n      <td>1,210.00</td>\n      <td>693.50</td>\n      <td>0.00 8/16/2019</td>\n      <td>8/15/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>07103</td>\n      <td>3698a3g</td>\n      <td>737.00 t2871216</td>\n      <td>Mark Woods\\n1,296.00</td>\n      <td>1,204.00</td>\n      <td>100.00</td>\n      <td>0.00 1/19/2018</td>\n      <td>2/18/2021</td>\n      <td>NaN</td>\n      <td>681.36</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>07104</td>\n      <td>3698a3g</td>\n      <td>737.00 t2742020</td>\n      <td>Kayode Holbrook\\n1,296.00</td>\n      <td>1,273.00</td>\n      <td>100.00</td>\n      <td>0.00 9/15/2020</td>\n      <td>9/14/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>07105</td>\n      <td>3698a2g</td>\n      <td>826.00 t2738920</td>\n      <td>Jonathan Robertson Jr\\n1,483.00</td>\n      <td>1,519.00</td>\n      <td>0.00</td>\n      <td>0.00 6/18/2020</td>\n      <td>6/17/2021</td>\n      <td>NaN</td>\n      <td>-247.58</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>07106</td>\n      <td>3698a5g</td>\n      <td>791.00 t3421286</td>\n      <td>William Fulton\\n1,408.00</td>\n      <td>1,530.00</td>\n      <td>100.00</td>\n      <td>0.00 10/27/2018</td>\n      <td>10/26/2020</td>\n      <td>NaN</td>\n      <td>118.00</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>07107</td>\n      <td>3698a4g</td>\n      <td>855.00 t2709215</td>\n      <td>David Harris\\n1,376.00</td>\n      <td>1,406.00</td>\n      <td>100.00</td>\n      <td>0.00 2/17/2020</td>\n      <td>2/16/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>07108</td>\n      <td>3698b3g</td>\n      <td>1,001.00 t2632603</td>\n      <td>Kaitlyn Skabo\\n1,626.00</td>\n      <td>1,575.00</td>\n      <td>200.00</td>\n      <td>200.00 2/9/2019</td>\n      <td>2/19/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>07109</td>\n      <td>3698b3g</td>\n      <td>1,001.00 t2708300</td>\n      <td>Jose Robles\\n1,626.00</td>\n      <td>1,390.00</td>\n      <td>100.00</td>\n      <td>200.00 2/12/2020</td>\n      <td>2/11/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>07110</td>\n      <td>3698a3ga</td>\n      <td>737.00 t2920470</td>\n      <td>Guadalupe Armstrong\\n1,295.00</td>\n      <td>1,259.00</td>\n      <td>100.00</td>\n      <td>0.00 2/9/2018</td>\n      <td>2/8/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>07111</td>\n      <td>3698b3g</td>\n      <td>1,001.00 t2712755</td>\n      <td>Billy Nail\\n1,626.00</td>\n      <td>1,584.00</td>\n      <td>200.00</td>\n      <td>0.00 4/24/2020</td>\n      <td>4/23/2021</td>\n      <td>NaN</td>\n      <td>-454.07</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>07112</td>\n      <td>3698b3g</td>\n      <td>1,001.00 t2754122</td>\n      <td>Wendy Bacon\\n1,726.00</td>\n      <td>1,607.00</td>\n      <td>200.00</td>\n      <td>200.00 9/12/2020</td>\n      <td>9/11/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>07113</td>\n      <td>3698a4g</td>\n      <td>855.00 t2710661</td>\n      <td>Janice Ahn\\n1,376.00</td>\n      <td>1,316.00</td>\n      <td>100.00</td>\n      <td>100.00 4/24/2020</td>\n      <td>4/23/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>07114</td>\n      <td>3698a5g</td>\n      <td>791.00 t0761733</td>\n      <td>Breanna Stewart\\n1,408.00</td>\n      <td>1,297.00</td>\n      <td>577.50</td>\n      <td>0.00 5/23/2014</td>\n      <td>5/8/2021</td>\n      <td>NaN</td>\n      <td>1,415.95</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>07115</td>\n      <td>3698a2g</td>\n      <td>826.00 t0734926</td>\n      <td>Joseph Sitters\\n1,483.00</td>\n      <td>1,354.00</td>\n      <td>100.00</td>\n      <td>0.00 5/2/2014</td>\n      <td>4/14/2021</td>\n      <td>NaN</td>\n      <td>66.06</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>07116</td>\n      <td>3698a3g</td>\n      <td>737.00 t2740896</td>\n      <td>Ferrin Bavousett\\n1,311.00</td>\n      <td>1,239.00</td>\n      <td>100.00</td>\n      <td>200.00 8/22/2020</td>\n      <td>8/21/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>07117</td>\n      <td>3698a3g</td>\n      <td>737.00 t2687782</td>\n      <td>Jeniva Marin\\n1,311.00</td>\n      <td>1,283.00</td>\n      <td>100.00</td>\n      <td>0.00 11/21/2019</td>\n      <td>11/20/2020</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>07118</td>\n      <td>3698a3g</td>\n      <td>737.00 t3455875</td>\n      <td>Trace Cooper\\n1,361.00</td>\n      <td>1,269.00</td>\n      <td>100.00</td>\n      <td>200.00 12/7/2018</td>\n      <td>1/6/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>07119</td>\n      <td>3698b2</td>\n      <td>1,259.00 t2708998</td>\n      <td>Tucker Mckinzie\\n1,838.00</td>\n      <td>1,771.00</td>\n      <td>200.00</td>\n      <td>200.00 9/29/2017</td>\n      <td>3/28/2021</td>\n      <td>NaN</td>\n      <td>-105.00</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>07120</td>\n      <td>3698b1</td>\n      <td>1,169.00 t3689489</td>\n      <td>Jatyn Taylor\\n1,742.00</td>\n      <td>1,640.00</td>\n      <td>200.00</td>\n      <td>0.00 2/16/2019</td>\n      <td>2/17/2021</td>\n      <td>NaN</td>\n      <td>10,716.62</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>07135</td>\n      <td>3698b1</td>\n      <td>1,169.00 t2766515</td>\n      <td>Darryl Whitaker Jr\\n1,742.00</td>\n      <td>1,742.00</td>\n      <td>0.00</td>\n      <td>0.00 10/17/2020</td>\n      <td>10/16/2021</td>\n      <td>NaN</td>\n      <td>-63.55</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>07201</td>\n      <td>3698b2</td>\n      <td>1,259.00 t3820388</td>\n      <td>Quinton Butler\\n1,903.00</td>\n      <td>1,549.00</td>\n      <td>200.00</td>\n      <td>0.00 4/26/2019</td>\n      <td>5/20/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>07202</td>\n      <td>3698a3</td>\n      <td>727.00 t2202133</td>\n      <td>Corey Miller\\n1,242.00</td>\n      <td>1,189.00</td>\n      <td>100.00</td>\n      <td>0.00 6/12/2016</td>\n      <td>4/11/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>07203</td>\n      <td>3698a3</td>\n      <td>727.00 t2705701</td>\n      <td>Matthew Martinez\\n1,242.00</td>\n      <td>1,102.00</td>\n      <td>100.00</td>\n      <td>0.00 2/28/2020</td>\n      <td>2/27/2021</td>\n      <td>NaN</td>\n      <td>202.00</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>07204</td>\n      <td>3698a3</td>\n      <td>727.00 VACANT</td>\n      <td>VACANT\\n1,192.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>07205</td>\n      <td>3698a2</td>\n      <td>819.00 t2896832</td>\n      <td>Kendra Pipkin\\n1,315.00</td>\n      <td>1,227.00</td>\n      <td>100.00</td>\n      <td>0.00 2/28/2018</td>\n      <td>3/27/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>07206</td>\n      <td>3698a5</td>\n      <td>789.00 t3825189</td>\n      <td>Hayato Kamohara\\n1,308.00</td>\n      <td>1,238.00</td>\n      <td>100.00</td>\n      <td>0.00 4/18/2019</td>\n      <td>3/17/2021</td>\n      <td>NaN</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Test get_header_start_end method\n",
    "header_start_end = nlp_proc.header_detector(df_detectron, mf_rr_kb).replace_header()\n",
    "header_start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detectron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,zscore = nlp_proc.header_detector(df_detectron, mf_rr_kb).get_header_candidates()\n",
    "z_df = pd.DataFrame(zscore, columns=['idx','v','z'])\n",
    "z_df['deltaz'] = z_df.z.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detectron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_header_start_end method\n",
    "start_end = nlp_proc.header_detector(df_textract, mf_rr_kb).get_header_start_end()\n",
    "start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final data frames with organized header\n",
    "tmp = nlp_proc.header_detector(df_textract, mf_rr_kb).replace_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test coercion to nuneric or date - if fails set as string, if doens't set data type\n",
    "num_table = df_detectron.apply(lambda x: organize.numeric_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut first rows of num_table that are all NaN\n",
    "num_table = num_table.dropna(how='all')\n",
    "data_start = num_table.index[0]\n",
    "# Calculate share of na rows per column\n",
    "na_share = num_table.isnull().sum() / len(num_table)\n",
    "na_share = na_share[na_share < 0.75]\n",
    "'''\n",
    "edited_table = orig_table.copy()\n",
    "for col in na_share.index:\n",
    "    edited_table[[col]] = num_table[[col]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_table.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "source": [
    "### Run function across all PDF output and save z_score full with diff to fine tune the delta threshold using data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Apply numeric-cleaner ($ and - handling)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### TODO: Apply DITTO to table reading \n",
    " 1. Read list of manually labelled rent rolls\n",
    " 2. Apply similarity based method for predicted vs. actual labelling\n",
    " 3. Leverage misclassified examples via similarity score as negative examples in language model fine tuning\n",
    " 4. Structure data to send through transformer model (potentially just use DITTO out of the box to begin)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}